py notes

for logistic regression it was OK to initialize the weights to zero, but this isn't OK for a neural network. In that case, you need to initialize them randomly

Why multiply the weights by a small number? x = np.random.randn((2,2)) * 0.01

for tanh and sigmoid, you want to keep the activation values close to zero to get a nice slope on the graph. If you're too far away the slope will be too small

Is 0.01 the best? No. It's OK for shallow networks, but not large ones


the bias does not have a symmetry problem, so you can initialize it as zeros



Can you do "!pip install <package>" from a Jupyter Notebook?